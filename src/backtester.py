"""
backtester.py
-------------
Simulates following WhaleTracker STRONG BUY signals over a chosen period
against a buy-and-hold SPY benchmark.

Data pipeline:
  ① Signal data    — read from data/historical_signals.json
                     (generated by scripts/precompute_signals.py — run once)
  ② Price data     — fetched from FMP API on each run (cached per session)

Strategy rules:
  • At each 13F signal_date (when all whale data became public):
      – Enter equal-weight positions in all STRONG BUY tickers
      – Exit positions that no longer meet the threshold
      – Rebalance remaining positions to equal weight
  • Benchmark: buy-and-hold SPY with the same initial capital
  • Trade execution price: closing price on signal_date
  • No transaction costs (disclosed in UI disclaimer)
  • Max positions cap to avoid over-concentration (default: 15)

Important timeline note:
  signal_date = max(filed_dates) across all whales for that quarter.
  This is the first date the investor would have had COMPLETE information.
  It is always 45–75 days after the quarter end (report_date).
"""

from __future__ import annotations

import json
import logging
import os
import time
from dataclasses import dataclass, field
from datetime import datetime
from pathlib import Path
from typing import Any

import pandas as pd
import requests
from dotenv import load_dotenv

load_dotenv()
logger = logging.getLogger(__name__)

_FMP_KEY  = os.getenv("FMP_API_KEY", "")
_FMP_BASE = "https://financialmodelingprep.com/api/v3"

_ROOT           = Path(__file__).parent.parent
_SIGNALS_FILE   = _ROOT / "data" / "historical_signals.json"
_PRICE_CACHE: dict[str, dict[str, pd.Series]] = {}   # (from, to) → {ticker: Series}

STRONG_BUY_MIN_SCORE = 6
BUY_MIN_SCORE        = 3


# ── Data classes ───────────────────────────────────────────────────────────────

@dataclass
class Trade:
    ticker:  str
    company: str
    action:  str       # "BUY" | "SELL"
    date:    str
    price:   float
    shares:  float
    value:   float
    signal:  str  = ""
    score:   float = 0.0


@dataclass
class QuarterSnapshot:
    label:        str           # "Q3 2024"
    report_date:  str           # "2024-09-30"
    signal_date:  str           # "2024-11-14"
    strong_buys:  list[str]     # tickers with STRONG BUY
    holdings:     list[str]     # actual positions entered
    port_value:   float = 0.0


@dataclass
class BacktestResult:
    portfolio_series:  pd.Series              # date str → portfolio USD value
    benchmark_series:  pd.Series              # date str → SPY USD value (normalised)
    trades:            list[Trade]  = field(default_factory=list)
    metrics:           dict         = field(default_factory=dict)
    quarterly_log:     list[QuarterSnapshot] = field(default_factory=list)
    signals_source:    str          = ""       # ISO timestamp of when signals were computed


# ── Signal data loader ────────────────────────────────────────────────────────

def load_historical_signals() -> dict | None:
    """Load pre-computed signals from data/historical_signals.json.

    Returns None if the file does not exist yet (run precompute_signals.py first).
    """
    if not _SIGNALS_FILE.exists():
        logger.warning(
            "[backtester] %s not found.  "
            "Run: python scripts/precompute_signals.py",
            _SIGNALS_FILE,
        )
        return None
    try:
        return json.loads(_SIGNALS_FILE.read_text())
    except Exception as exc:
        logger.error("[backtester] Failed to load signals file: %s", exc)
        return None


def signals_computed_at() -> str | None:
    """Return ISO timestamp of when the signals file was last computed, or None."""
    data = load_historical_signals()
    return data["meta"].get("computed_at") if data else None


# ── FMP price helpers ─────────────────────────────────────────────────────────

def _fetch_prices_fmp(
    tickers:   list[str],
    from_date: str,
    to_date:   str,
) -> dict[str, pd.Series]:
    """Fetch daily EOD close prices from FMP for multiple tickers.

    Returns {TICKER: pd.Series(date_str → close)}, sorted ascending.
    Uses a module-level session cache keyed by (from_date, to_date) so that
    repeated backtest runs in the same process are instant.
    """
    if not _FMP_KEY:
        logger.warning("[backtester] FMP_API_KEY not set — no price data available")
        return {}

    cache_key = (from_date, to_date)
    if cache_key not in _PRICE_CACHE:
        _PRICE_CACHE[cache_key] = {}
    cache = _PRICE_CACHE[cache_key]

    missing = [t for t in tickers if t not in cache]
    if not missing:
        return {t: cache[t] for t in tickers}

    def _store(data: dict, fallback_sym: str) -> None:
        if "historicalStockList" in data:
            for item in data["historicalStockList"]:
                sym  = item.get("symbol", "").upper()
                hist = item.get("historical", [])
                if hist:
                    cache[sym] = pd.Series(
                        {row["date"]: row["close"] for row in hist},
                        dtype=float,
                    ).sort_index()
        elif "historical" in data:
            hist = data["historical"]
            if hist:
                cache[fallback_sym.upper()] = pd.Series(
                    {row["date"]: row["close"] for row in hist},
                    dtype=float,
                ).sort_index()

    batch_size = 5
    for i in range(0, len(missing), batch_size):
        batch   = [t.upper() for t in missing[i:i + batch_size]]
        symbols = ",".join(batch)
        try:
            r = requests.get(
                f"{_FMP_BASE}/historical-price-full/{symbols}",
                params={"from": from_date, "to": to_date, "apikey": _FMP_KEY},
                timeout=30,
            )
            r.raise_for_status()
            _store(r.json(), batch[0])
        except Exception as exc:
            logger.warning("[backtester] FMP price fetch failed (%s): %s", symbols, exc)
        if i + batch_size < len(missing):
            time.sleep(0.4)

    return {t: cache[t] for t in tickers if t in cache}


def _price_on(prices: dict[str, pd.Series], ticker: str, date_str: str) -> float | None:
    """Closest available close price for `ticker` at or before `date_str`."""
    s = prices.get(ticker.upper())
    if s is None or s.empty:
        return None
    sub = s[s.index <= date_str]
    if sub.empty:
        sub = s
    return float(sub.iloc[-1])


# ── Simulation ────────────────────────────────────────────────────────────────

def run_backtest(
    years:           int   = 3,
    initial_capital: float = 100_000.0,
    min_signal:      str   = "STRONG BUY",
    max_positions:   int   = 15,
) -> BacktestResult | None:
    """
    Simulate following WhaleTracker signals over `years` years.

    Returns BacktestResult on success, None on critical data failure.

    Failure modes handled gracefully:
      • historical_signals.json not found     → returns None (show setup message)
      • No quarters in the requested window   → returns None
      • FMP price data unavailable for a ticker → that ticker is skipped
      • SPY prices unavailable                → returns None
    """
    # ── 1. Load pre-computed signals ─────────────────────────────────────────
    signal_data = load_historical_signals()
    if signal_data is None:
        return None

    quarters_all: list[dict] = signal_data.get("quarters", [])
    computed_at = signal_data.get("meta", {}).get("computed_at", "")

    # ── 2. Filter to the requested backtest window ────────────────────────────
    end_date   = datetime.utcnow().date()
    start_dt   = end_date.replace(year=end_date.year - years)
    from_str   = start_dt.strftime("%Y-%m-%d")
    to_str     = end_date.strftime("%Y-%m-%d")

    quarters_in_window = [
        q for q in quarters_all
        if q["signal_date"] >= from_str
    ]
    # Sort oldest → newest
    quarters_in_window.sort(key=lambda q: q["signal_date"])

    if len(quarters_in_window) < 2:
        logger.warning(
            "[backtester] Only %d quarter(s) in the %d-year window — "
            "run precompute_signals.py --years %d to extend history.",
            len(quarters_in_window), years, years,
        )
        return None

    logger.info("[backtester] %d-year sim | %d quarters | capital=%.0f | signal=%s",
                years, len(quarters_in_window), initial_capital, min_signal)

    # ── 3. Determine which tickers we need prices for ─────────────────────────
    min_score = STRONG_BUY_MIN_SCORE if min_signal == "STRONG BUY" else BUY_MIN_SCORE
    all_tickers: set[str] = {"SPY"}

    for q in quarters_in_window:
        for ticker, info in q["tickers"].items():
            if info.get("score", 0) >= min_score:
                all_tickers.add(ticker)

    logger.info("[backtester] Fetching prices for %d tickers (%s → %s) …",
                len(all_tickers), from_str, to_str)

    # ── 4. Fetch historical prices ────────────────────────────────────────────
    all_prices = _fetch_prices_fmp(sorted(all_tickers), from_str, to_str)

    spy_series = all_prices.get("SPY", pd.Series(dtype=float))
    if spy_series.empty:
        logger.error("[backtester] SPY price data unavailable — aborting.")
        return None

    # ── 5. Day-by-day simulation ──────────────────────────────────────────────
    trading_days = spy_series.index.tolist()   # sorted date strings
    spy_start    = float(spy_series.iloc[0])
    spy_shares   = initial_capital / spy_start

    cash         = initial_capital
    positions:   dict[str, float] = {}    # ticker → shares held
    cost_basis:  dict[str, float] = {}    # ticker → avg cost per share
    trades:      list[Trade]      = []
    q_log:       list[QuarterSnapshot] = []

    port_vals:  dict[str, float] = {}
    bench_vals: dict[str, float] = {}
    q_idx = 0   # pointer into quarters_in_window

    for day in trading_days:
        # ── Rebalance on signal_date arrival ─────────────────────────────────
        while (q_idx < len(quarters_in_window)
               and quarters_in_window[q_idx]["signal_date"] <= day):

            q      = quarters_in_window[q_idx]
            scores = q["tickers"]

            # Select tickers meeting threshold, sorted by score desc, capped
            candidates = sorted(
                [t for t, info in scores.items()
                 if info.get("score", 0) >= min_score
                 and t in all_prices],              # only if we have price data
                key=lambda t: scores[t]["score"],
                reverse=True,
            )[:max_positions]
            target_set  = set(candidates)
            current_set = set(positions.keys())

            # Current portfolio value before rebalancing
            port_now = cash + sum(
                positions[t] * (_price_on(all_prices, t, day) or cost_basis.get(t, 0))
                for t in positions
            )

            # ── Exit positions leaving the target set ─────────────────────────
            for ticker in list(current_set - target_set):
                px = _price_on(all_prices, ticker, day)
                if px and positions.get(ticker, 0) > 0:
                    shares = positions[ticker]
                    val    = shares * px
                    cash  += val
                    trades.append(Trade(
                        ticker  = ticker,
                        company = scores.get(ticker, {}).get("company", ticker),
                        action  = "SELL",
                        date    = day,
                        price   = px,
                        shares  = shares,
                        value   = val,
                    ))
                    del positions[ticker]
                    del cost_basis[ticker]

            # ── Equal-weight target value per position ────────────────────────
            n_targets = len(target_set)
            if n_targets == 0:
                q_idx += 1
                continue

            port_now   = cash + sum(
                positions[t] * (_price_on(all_prices, t, day) or cost_basis.get(t, 0))
                for t in positions
            )
            target_val = port_now / n_targets

            # ── Enter / rebalance positions ───────────────────────────────────
            for ticker in candidates:
                px = _price_on(all_prices, ticker, day)
                if not px or px <= 0:
                    continue

                if ticker in positions:
                    # Trim or add to existing — only rebalance if drift > $50
                    current_val = positions[ticker] * px
                    diff        = target_val - current_val
                    if abs(diff) < 50:
                        continue
                    adj_shares        = diff / px
                    positions[ticker] += adj_shares
                    cash              -= diff
                else:
                    # New position
                    avail_per_new = (
                        cash * 0.9 / max(len(target_set - current_set), 1)
                    )
                    invest = min(target_val, avail_per_new)
                    if invest < 10:
                        continue
                    shares = invest / px
                    positions[ticker]  = shares
                    cost_basis[ticker] = px
                    cash              -= invest
                    info               = scores.get(ticker, {})
                    trades.append(Trade(
                        ticker  = ticker,
                        company = info.get("company", ticker),
                        action  = "BUY",
                        date    = day,
                        price   = px,
                        shares  = shares,
                        value   = invest,
                        signal  = info.get("recommendation", ""),
                        score   = info.get("score", 0.0),
                    ))

            q_log.append(QuarterSnapshot(
                label       = q.get("label", ""),
                report_date = q.get("report_date", ""),
                signal_date = q.get("signal_date", ""),
                strong_buys = [t for t, v in scores.items()
                               if v.get("recommendation") == "STRONG BUY"],
                holdings    = list(target_set),
                port_value  = port_now,
            ))
            q_idx += 1

        # ── Daily mark-to-market ──────────────────────────────────────────────
        port_val = max(cash, 0) + sum(
            positions.get(t, 0) * (_price_on(all_prices, t, day) or 0)
            for t in positions
        )
        spy_px   = spy_series.get(day, spy_start)
        port_vals[day]  = port_val
        bench_vals[day] = spy_px / spy_start * initial_capital

    # ── 6. Metrics ────────────────────────────────────────────────────────────
    port_s  = pd.Series(port_vals,  dtype=float).sort_index()
    bench_s = pd.Series(bench_vals, dtype=float).sort_index()
    metrics = _calc_metrics(port_s, bench_s, initial_capital)
    metrics["n_trades"] = len(trades)

    logger.info(
        "[backtester] Done — return %.1f%%, SPY %.1f%%, alpha %.1f%%",
        metrics.get("total_return_pct", 0),
        metrics.get("benchmark_return_pct", 0),
        metrics.get("alpha_pct", 0),
    )

    return BacktestResult(
        portfolio_series = port_s,
        benchmark_series = bench_s,
        trades           = trades,
        metrics          = metrics,
        quarterly_log    = q_log,
        signals_source   = computed_at,
    )


# ── Metrics ───────────────────────────────────────────────────────────────────

def _calc_metrics(
    port:    pd.Series,
    bench:   pd.Series,
    capital: float,
    rf:      float = 0.05,
) -> dict:
    if port.empty or capital == 0:
        return {}

    total_ret  = (port.iloc[-1]  - capital) / capital
    bench_ret  = (bench.iloc[-1] - capital) / capital

    try:
        d0   = datetime.strptime(str(port.index[0]),  "%Y-%m-%d")
        d1   = datetime.strptime(str(port.index[-1]), "%Y-%m-%d")
        days = max((d1 - d0).days, 1)
    except Exception:
        days = 365
    years = days / 365.25

    ann_ret   = (1 + total_ret) ** (1 / years) - 1 if years > 0 else total_ret
    daily_ret = port.pct_change().dropna()
    ann_std   = daily_ret.std() * (252 ** 0.5) if not daily_ret.empty else 0.01
    sharpe    = (ann_ret - rf) / ann_std if ann_std > 0 else 0.0

    roll_max = port.cummax()
    drawdown = (port - roll_max) / roll_max
    max_dd   = float(drawdown.min())

    try:
        port_dt = port.copy()
        port_dt.index = pd.to_datetime(port_dt.index)
        monthly  = port_dt.resample("ME").last().pct_change().dropna()
        win_rate = float((monthly > 0).sum() / len(monthly)) if len(monthly) > 0 else 0.5
    except Exception:
        win_rate = 0.5

    return {
        "total_return_pct":      round(total_ret  * 100, 2),
        "benchmark_return_pct":  round(bench_ret  * 100, 2),
        "alpha_pct":             round((total_ret - bench_ret) * 100, 2),
        "annualized_return_pct": round(ann_ret    * 100, 2),
        "max_drawdown_pct":      round(max_dd     * 100, 2),
        "sharpe_ratio":          round(sharpe,           2),
        "win_rate_pct":          round(win_rate   * 100, 1),
        "final_value":           round(float(port.iloc[-1]), 2),
        "n_trades":              0,   # overwritten after call
    }
